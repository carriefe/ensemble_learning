{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "475e1682"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim # Sets of preset layers and optimizers\n",
        "import torch.nn.functional as F # Sets of functions such as ReLU\n",
        "import torchvision as tv\n",
        "# Step 1: Let's import some libraries!\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as tt\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from torchvision import datasets, transforms # Popular datasets, architectures and common image transformations for computer vision"
      ],
      "id": "475e1682"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd63463b"
      },
      "outputs": [],
      "source": [
        "def load_mnist(batch_size=32, train=True):\n",
        "\n",
        "    '''\n",
        "    Using the dataset and dataloader classes you should be able to make an MNIST set and loader\n",
        "    the loader should use the 'batch_size' argument and the dataset should use'train'\n",
        "\n",
        "    Also, the 'ToTensor' transform is given, you should set the transform of the dataset to just this\n",
        "    '''\n",
        "    to_tensor_transform = torchvision.transforms.ToTensor()\n",
        "    dataset = torchvision.datasets.MNIST(root = \"./data\", train = train,transform = to_tensor_transform,download = True )\n",
        "    dataloader = DataLoader(dataset,batch_size = batch_size, shuffle = True )\n",
        "\n",
        "    return dataset, dataloader"
      ],
      "id": "dd63463b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7be28bc4"
      },
      "outputs": [],
      "source": [
        "def plot_image_and_label(image, raw_output_from_model):\n",
        "\n",
        "    '''\n",
        "    Takes in an image and label and shows them using matplotlib\n",
        "    this is used to visualize the data and also the outputs of our network\n",
        "    '''\n",
        "\n",
        "    plt.imshow(image)\n",
        "    if type(raw_output_from_model) is not int:\n",
        "        _,predicted = torch.max(raw_output_from_model,1)\n",
        "#         Takes 1 highest number from the output\n",
        "        plt.title(\"Best label = \" + str(predicted.item()) + \", with Score: \" + str(round(raw_output_from_model[0][predicted].item() * 100,2)))\n",
        "    else:\n",
        "        plt.title(\"Label = \" + str(raw_output_from_model))\n",
        "    plt.show()\n",
        "    return"
      ],
      "id": "7be28bc4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "adcd23b7",
        "outputId": "9953a5d1-ffe0-4ec3-b433-dd22011e5fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28]) ex_image.shape\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# This will just test whether your dataset and loader work\n",
        "# They might still have issues, but if an example image shows here you're on the right track!\n",
        "train_data,train_dataloader = load_mnist(batch_size = 64, train = True)\n",
        "ex_image, ex_label = train_data[random.randint(0,1000)]\n",
        "print(ex_image.shape,'ex_image.shape')\n",
        "plot_image_and_label(ex_image.reshape(28,28), ex_label)"
      ],
      "id": "adcd23b7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b079fcda"
      },
      "outputs": [],
      "source": [
        "class MyMLP(nn.Module):\n",
        "    def __init__(self,input_size, output_size):\n",
        "        super().__init__()\n",
        "#         self.conv1 = nn.conv2d(in_channels = 1, out_channels = 3, stride = 1, padding =)\n",
        "        self.input_size = input_size\n",
        "        self.lin1 = nn.Linear(input_size,256)\n",
        "        self.lin2 = nn.Linear(256,128)\n",
        "        self.lin3 = nn.Linear(128,output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = x.view(-1, self.input_size)\n",
        "        out = self.lin1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.lin2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.lin3(out)\n",
        "        out = self.relu(out)\n",
        "        return out"
      ],
      "id": "b079fcda"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "240af524",
        "outputId": "7df91678-2e97-4daa-a21e-b767857826fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28]) eximage.shape\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Shows the prediction of the model without training\n",
        "# Not very good huh? (though theres a small chance it is lol)\n",
        "\n",
        "test_model = MyMLP(784, 2)\n",
        "test_output = test_model(ex_image.flatten()) # Notice how we flatten the 2d image into 1d to use the MLP\n",
        "print(ex_image.shape,\"eximage.shape\")\n",
        "plot_image_and_label(ex_image.reshape(28,28), test_output)"
      ],
      "id": "240af524"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e510c774"
      },
      "outputs": [],
      "source": [
        "bits = []\n",
        "def generateAllBinaryStrings(n, arr, i,num):\n",
        "    if i == n:\n",
        "        key = ''.join([str(i) for i in arr])\n",
        "        bits.append(key)\n",
        "        num += 1\n",
        "        return\n",
        "\n",
        "    # First assign \"0\" at ith position\n",
        "    # and try for all other permutations\n",
        "    # for remaining positions\n",
        "    arr[i] = 0\n",
        "    generateAllBinaryStrings(n, arr, i + 1,num+1)\n",
        "\n",
        "    # And then assign \"1\" at ith position\n",
        "    # and try for all other permutations\n",
        "    # for remaining positions\n",
        "    arr[i] = 1\n",
        "    generateAllBinaryStrings(n, arr, i + 1,num+1)\n",
        "num = 0\n",
        "generateAllBinaryStrings(4,[0]*4 , 0,num)\n"
      ],
      "id": "e510c774"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4502a269",
        "outputId": "706cbad4-3ace-4d2f-f914-be6dd60e6e30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0000', '0001', '0010', '0011', '0100', '0101', '0110', '0111', '1000', '1001', '1010', '1011', '1100', '1101', '1110', '1111']\n",
            "{0: '0000', 1: '0001', 2: '0010', 3: '0011', 4: '0100', 5: '0101', 6: '0110', 7: '0111', 8: '1000', 9: '1001', 10: '1010', 11: '1011', 12: '1100', 13: '1101', 14: '1110', 15: '1111'}\n"
          ]
        }
      ],
      "source": [
        "print(bits)\n",
        "mapping = {}\n",
        "curr_index = 0\n",
        "invMapping = {}\n",
        "for index,bit in enumerate(bits):\n",
        "    mapping[index] = bit\n",
        "    invMapping[bit] = index\n",
        "print(mapping)\n",
        "# Unbalanced : ['0000', '0001', '0010', '0011', '0100', '0101', '0110', '0111', '1000', '1001', '1010', '1011', '1100', '1101', '1110', '1111']\n",
        "# {0: '1111', 1: '0001', 2: '0010', 3: '0011', 4: '0100', 5: '0101', 6: '0110', 7: '0111', 8: '1000', 9: '1001'}\n",
        "# Balanced :"
      ],
      "id": "4502a269"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c32440bd"
      },
      "outputs": [],
      "source": [
        "def training(modelname,model, loss_function, optimizer, train_dataloader, n_epochs, update_interval):\n",
        "\n",
        "    '''\n",
        "    Updates the parameters of the given model using the optimizer of choice to\n",
        "    reduce the given loss_function\n",
        "\n",
        "    This will iterate over the dataloader 'n_epochs' times training on each batch of images\n",
        "\n",
        "    To get the gradient (which is stored internally in the model) use .backward() from the loss tensor\n",
        "    and to apply it use .step() on the optimizer\n",
        "\n",
        "    In between steps you need to zero the gradient so it can be recalculated -- use .zero_grad for this\n",
        "    '''\n",
        "\n",
        "    losses = []\n",
        "    part_loss = []\n",
        "    for n in range(n_epochs):\n",
        "        for i, (image, label) in enumerate(tqdm(iter(train_dataloader))):\n",
        "\n",
        "            # TODO Complete the training loop using the instructions above\n",
        "            # Hint: the above code essentially does one training step\n",
        "\n",
        "            ##############################################################\n",
        "            optimizer.zero_grad()\n",
        "            my_output = model(image)\n",
        "            if modelname == 'model1':\n",
        "                new_label = torch.Tensor([int(mapping[int(l)][0]) for l in label]).long()\n",
        "            elif modelname == 'model2':\n",
        "                new_label = torch.Tensor([int(mapping[int(l)][1]) for l in label]).long()\n",
        "            elif modelname == 'model3':\n",
        "                new_label = torch.Tensor([int(mapping[int(l)][2]) for l in label]).long()\n",
        "            elif modelname == 'model4':\n",
        "                new_label = torch.Tensor([int(mapping[int(l)][3]) for l in label]).long()\n",
        "            elif modelname == 'model':\n",
        "                new_label = label\n",
        "            loss = loss_function(my_output,new_label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            part_loss.append(loss.item())\n",
        "            ##############################################################\n",
        "\n",
        "            if i % update_interval == 0:\n",
        "                losses.append(sum(part_loss)/len(part_loss)) # This will append your losses for plotting -- please use \"loss\" as the name for your loss\n",
        "#                 part_loss = []\n",
        "    return model, losses"
      ],
      "id": "c32440bd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTBrJRHTiH-A",
        "outputId": "c6bcd268-a834-419a-851e-793170fca301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing the previously trained model on test dataset of MNIST\n"
          ]
        }
      ],
      "source": [
        "print(\"testing the previously trained model on test dataset of MNIST\")\n",
        "test_dataset, test_dataloader = load_mnist(batch_size=10000, train=False)"
      ],
      "id": "vTBrJRHTiH-A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUxGkM22hv_8"
      },
      "outputs": [],
      "source": [
        "def testing(modelname, model, loss_function, test_data):\n",
        "    sum_loss = 0\n",
        "    n_correct = 0\n",
        "    total = 0\n",
        "    for i, (image, label) in enumerate(tqdm(iter(test_data))):\n",
        "        pred = model(image)\n",
        "        if modelname == 'model1':\n",
        "            new_label =  torch.Tensor([int(mapping[int(l)][0]) for l in label]).long()\n",
        "        elif modelname == 'model2':\n",
        "            new_label = torch.Tensor([int(mapping[int(l)][0]) for l in label]).long()\n",
        "        elif modelname == 'model3':\n",
        "            new_label = torch.Tensor([int(mapping[int(l)][0]) for l in label]).long()\n",
        "        elif modelname == 'model4':\n",
        "            new_label = torch.Tensor([int(mapping[int(l)][0]) for l in label]).long()\n",
        "        elif modelname == 'model':\n",
        "            new_label = label\n",
        "        loss = loss_function(pred,new_label)\n",
        "        sum_loss += loss.item()\n",
        "        _, predicted = torch.max(pred,1)\n",
        "        n_correct += (predicted == new_label).sum()\n",
        "        total += new_label.size(0)\n",
        "\n",
        "    test_acc = round(((n_correct / total).item() * 100), 2)\n",
        "    avg_loss = round(sum_loss / len(test_data), 2)\n",
        "\n",
        "    print(\"test accuracy:\", test_acc)\n",
        "    print(\"test loss:\", avg_loss )\n",
        "\n",
        "    return test_acc, avg_loss\n"
      ],
      "id": "WUxGkM22hv_8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2a16afd"
      },
      "outputs": [],
      "source": [
        "# Plug in your model, loss function, and optimizer\n",
        "# Try out different hyperparameters and different models to see how they perform\n",
        "\n",
        "lr = 0.0009          # The size of the step taken when doing gradient descent 0.01 0.001 0.0001\n",
        "batch_size = 400        # The number of images being trained on at once\n",
        "update_interval = 100   # The number of batches trained on before recording loss\n",
        "n_epochs = 3           # The number of times we train through the entire dataset 5 10 15\n",
        "\n",
        "train_dataset, train_dataloader = load_mnist(batch_size=batch_size, train=True)\n",
        "\n",
        "model = MyMLP(784, 2)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
      ],
      "id": "c2a16afd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "f579218b",
        "outputId": "7d1f9283-c374-416c-849a-a2d455cfa3ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [00:06<00:00, 21.97it/s]\n",
            "100%|██████████| 150/150 [00:08<00:00, 17.64it/s]\n",
            "100%|██████████| 150/150 [00:06<00:00, 21.86it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Training Model 1\n",
        "model1 = MyMLP(784, 2)\n",
        "trained_model1, losses1 = training('model1',model1, loss_function, optimizer, train_dataloader, n_epochs=n_epochs, update_interval=update_interval)\n",
        "\n",
        "plt.plot(np.arange(len(losses1)) * batch_size * update_interval, losses1)\n",
        "plt.title(\"training curve1\")\n",
        "plt.xlabel(\"number of images trained on\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()\n"
      ],
      "id": "f579218b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py95HPXyhsjr",
        "outputId": "4a082ce3-acea-40c7-b14d-1820c03c360e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy: 80.16\n",
            "test loss: 0.67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Testing Model1\n",
        "_,_ = testing('model1', trained_model1, loss_function, test_dataloader)\n"
      ],
      "id": "Py95HPXyhsjr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fs6ynyp7kmaH"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.svm import SVC\n",
        "# clf = GridSearchCV(SVC(kernel='linear', C=1,gamma=1),{\n",
        "#     'lr':[0.01,0.001,0.0001,0.00001],\n",
        "#     'n_epochs':[5,10,15]\n",
        "# },cv=5, return_train_score=False)\n",
        "\n",
        "# trained_model1, losses1 = training('model1',model1, loss_function, optimizer, train_dataloader, n_epochs=n_epochs, update_interval=update_interval)\n",
        "# clf.cv_results_\n",
        "# 0.008\n"
      ],
      "id": "Fs6ynyp7kmaH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "T6eTuCwRpPb1",
        "outputId": "66188330-8481-4154-fda0-e9a34616204d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▊ | 133/150 [00:06<00:00, 19.58it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-31009cfc69a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_lr\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbest_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_n_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mbest_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_n_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_n_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-31009cfc69a7>\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m(model, input_shape, compression_size, test_data)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn_epochs_lst\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_size_lst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-315111d5e79d>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(modelname, model, loss_function, optimizer, train_dataloader, n_epochs, update_interval)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpart_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# TODO Complete the training loop using the instructions above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#hyperparameter tuning model1\n",
        "import math\n",
        "def grid_search(model,input_shape,compression_size,test_data):\n",
        "    \"\"\"\n",
        "    model : Trained model\n",
        "    test_data : test data = dataset[30000//batch_size:]\n",
        "    input_shape :input size of images\n",
        "    compression_size :  size of bottleneck\n",
        "    \"\"\"\n",
        "    e = math.e\n",
        "    learning_rate = [0.1,0.001,0.01,0.0001,0.00001]\n",
        "    n_epochs_lst = [5,10,15]\n",
        "    batch_size_lst = [120,500]\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    accuracy = float('-inf')\n",
        "    best_lr = 0\n",
        "    update_interval = 100\n",
        "    best_batch = 0\n",
        "    best_n_epochs = 0\n",
        "    for lr in learning_rate:\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "        for n_epochs in n_epochs_lst :\n",
        "            trained_model, losses = training('model1',model, loss_function, optimizer, train_dataloader, n_epochs, update_interval)\n",
        "            for batch_size in batch_size_lst:\n",
        "                print(batch_size)\n",
        "                print(lr)\n",
        "                print(n_epochs)\n",
        "                test_loss, test_accuracy = testing('model1', model, loss_function, test_dataloader)\n",
        "                if test_accuracy >= accuracy:\n",
        "                    best_lr = lr\n",
        "                    best_batch = batch_size\n",
        "                    best_n_epochs = n_epochs\n",
        "                    accuracy = test_accuracy\n",
        "\n",
        "    return best_lr , best_batch, best_n_epochs,test_accuracy\n",
        "\n",
        "best_lr,best_batch_size, best_n_epochs,best_acc = grid_search(trained_model1, 784, 2, test_dataset)\n",
        "print(best_lr,best_batch_size, best_n_epochs, best_acc)"
      ],
      "id": "T6eTuCwRpPb1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9pWUz0R4JVQ"
      },
      "outputs": [],
      "source": [
        "# lr = 0.0008      # The size of the step taken when doing gradient descent\n",
        "# batch_size =500      # The number of images being trained on at once\n",
        "# update_interval = 100   # The number of batches trained on before recording loss\n",
        "# n_epochs = 10\n",
        "# test_accuracy, test_loss = testing('model1', model, loss_function, test_dataloader)\n",
        "# print(test_loss, test_accuracy)\n",
        "# print(best_lr,loss,test_accuracy)"
      ],
      "id": "e9pWUz0R4JVQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "481b1ad5"
      },
      "outputs": [],
      "source": [
        "lr = 0.0009       # The size of the step taken when doing gradient descent\n",
        "batch_size = 1000  # The number of images being trained on at once\n",
        "update_interval = 100   # The number of batches trained on before recording loss\n",
        "n_epochs = 10         # The number of times we train through the entire dataset\n",
        "\n",
        "train_dataset, train_dataloader = load_mnist(batch_size=batch_size, train=True)\n",
        "\n",
        "model = MyMLP(784, 2)\n",
        "loss_function = nn.CrossEntropyLoss()\n"
      ],
      "id": "481b1ad5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ca882a2"
      },
      "outputs": [],
      "source": [
        "# Training Model 2\n",
        "model2 = MyMLP(784, 2)\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=lr)\n",
        "trained_model2, losses2 = training('model2',model2, loss_function, optimizer, train_dataloader, n_epochs=n_epochs, update_interval=update_interval)\n",
        "\n",
        "plt.plot(np.arange(len(losses2)) * batch_size * update_interval, losses2)\n",
        "plt.title(\"training curve2\")\n",
        "plt.xlabel(\"number of images trained on\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()\n"
      ],
      "id": "6ca882a2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xa-8-zbpiAW1"
      },
      "outputs": [],
      "source": [
        "# Testing Model2\n",
        "_,_ = testing('model2', trained_model2, loss_function, test_dataloader)\n"
      ],
      "id": "Xa-8-zbpiAW1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSK4vLGhybZS"
      },
      "outputs": [],
      "source": [
        "# Model2 Hyperparameter Tuning\n",
        "def grid_search(model,input_shape,compression_size,test_data):\n",
        "    \"\"\"\n",
        "    model : Trained model\n",
        "    test_data : test data = dataset[30000//batch_size:]\n",
        "    input_shape :input size of images\n",
        "    compression_size :  size of bottleneck\n",
        "    \"\"\"\n",
        "    e = math.e\n",
        "    learning_rate = [0.0008,0.0009,0.009,0.00001,0.001]\n",
        "    n_epochs_lst = [5,10,8,3]\n",
        "    batch_size_lst = [120,300,500,800,1000]\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    loss = float('inf')\n",
        "    best_lr = 0\n",
        "    update_interval = 100\n",
        "    best_batch = 0\n",
        "    best_n_epochs = 0\n",
        "    for lr in learning_rate:\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "        for n_epochs in n_epochs_lst :\n",
        "            trained_model, losses = training('model2',model, loss_function, optimizer, train_dataloader, n_epochs, update_interval)\n",
        "            for batch_size in batch_size_lst:\n",
        "                print(batch_size)\n",
        "                print(lr)\n",
        "                print(n_epochs)\n",
        "                test_loss, test_accuracy = testing('model2', model, loss_function, test_dataloader)\n",
        "                if test_loss <= loss:\n",
        "                    best_lr = lr\n",
        "                    best_batch = batch_size\n",
        "                    best_n_epochs = n_epochs\n",
        "                    loss = test_loss\n",
        "\n",
        "    return best_lr , best_batch, best_n_epochs,loss\n",
        "\n",
        "best_lr,best_batch_size, best_n_epochs,loss = grid_search(trained_model2, 784, 2, test_dataset)\n",
        "print(best_lr,best_batch_size, best_n_epochs, loss)"
      ],
      "id": "YSK4vLGhybZS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "562f58aa"
      },
      "outputs": [],
      "source": [
        "lr = 0.0008            # The size of the step taken when doing gradient descent\n",
        "batch_size = 128        # The number of images being trained on at once\n",
        "update_interval = 100   # The number of batches trained on before recording loss\n",
        "n_epochs = 3            # The number of times we train through the entire dataset\n",
        "\n",
        "train_dataset, train_dataloader = load_mnist(batch_size=batch_size, train=True)\n",
        "\n",
        "model = MyMLP(784, 2)\n",
        "loss_function = nn.CrossEntropyLoss()\n"
      ],
      "id": "562f58aa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecea8daf"
      },
      "outputs": [],
      "source": [
        "# Training Model 3\n",
        "model3 = MyMLP(784, 2)\n",
        "optimizer = torch.optim.Adam(model3.parameters(), lr=lr)\n",
        "trained_model3, losses3 = training('model3',model3, loss_function, optimizer, train_dataloader, n_epochs=n_epochs, update_interval=update_interval)\n",
        "\n",
        "plt.plot(np.arange(len(losses3)) * batch_size * update_interval, losses3)\n",
        "plt.title(\"training curve3\")\n",
        "plt.xlabel(\"number of images trained on\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()\n"
      ],
      "id": "ecea8daf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjGVOkqNiDWI"
      },
      "outputs": [],
      "source": [
        "# Testing Model3\n",
        "_,_ = testing('model3' ,trained_model3, loss_function, test_dataloader)"
      ],
      "id": "ZjGVOkqNiDWI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQajExZw2Pnq"
      },
      "outputs": [],
      "source": [
        "# Model3 Hyperparameter Tuning\n",
        "def grid_search(model,input_shape,compression_size,test_data):\n",
        "    \"\"\"\n",
        "    model : Trained model\n",
        "    test_data : test data = dataset[30000//batch_size:]\n",
        "    input_shape :input size of images\n",
        "    compression_size :  size of bottleneck\n",
        "    \"\"\"\n",
        "    e = math.e\n",
        "    learning_rate = [0.0008,0.0009,0.00095,0.0001]\n",
        "    n_epochs_lst = [5,10,15]\n",
        "    batch_size_lst = [500,800,1000,1300,1500]\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    loss = float('inf')\n",
        "    best_lr = 0\n",
        "    update_interval = 100\n",
        "    best_batch = 0\n",
        "    best_n_epochs = 0\n",
        "    for lr in learning_rate:\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "        for n_epochs in n_epochs_lst :\n",
        "            trained_model, losses = training('model3',model, loss_function, optimizer, train_dataloader, n_epochs, update_interval)\n",
        "            for batch_size in batch_size_lst:\n",
        "                print(batch_size)\n",
        "                print(lr)\n",
        "                print(n_epochs)\n",
        "                test_loss, test_accuracy = testing('model3', model, loss_function, test_dataloader)\n",
        "                if test_loss <= loss:\n",
        "                    best_lr = lr\n",
        "                    best_batch = batch_size\n",
        "                    best_n_epochs = n_epochs\n",
        "                    loss = test_loss\n",
        "\n",
        "    return best_lr , best_batch, best_n_epochs,loss\n",
        "\n",
        "best_lr,best_batch_size, best_n_epochs,loss = grid_search(trained_model3, 784, 2, test_dataset)\n",
        "print(best_lr,best_batch_size, best_n_epochs, loss)"
      ],
      "id": "RQajExZw2Pnq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0906925"
      },
      "outputs": [],
      "source": [
        "lr = 0.0008            # The size of the step taken when doing gradient descent\n",
        "batch_size = 128        # The number of images being trained on at once\n",
        "update_interval = 100   # The number of batches trained on before recording loss\n",
        "n_epochs = 3            # The number of times we train through the entire dataset\n",
        "\n",
        "train_dataset, train_dataloader = load_mnist(batch_size=batch_size, train=True)\n",
        "\n",
        "model4 = MyMLP(784, 2)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model4.parameters(), lr=lr)"
      ],
      "id": "f0906925"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c621ddd3"
      },
      "outputs": [],
      "source": [
        "#  Training Model 4\n",
        "trained_model4, losses4 = training('model4',model4, loss_function, optimizer, train_dataloader, n_epochs=n_epochs, update_interval=update_interval)\n",
        "plt.plot(np.arange(len(losses4)) * batch_size * update_interval, losses4)\n",
        "plt.title(\"training curve4\")\n",
        "plt.xlabel(\"number of images trained on\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()\n"
      ],
      "id": "c621ddd3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffcfa9ab"
      },
      "outputs": [],
      "source": [
        "# Testing Model4\n",
        "_,_ = testing('model4', trained_model4, loss_function, test_dataloader)"
      ],
      "id": "ffcfa9ab"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac53287e"
      },
      "outputs": [],
      "source": [
        "# Model4 Hyperparameter Tuning\n",
        "def grid_search(model,input_shape,compression_size,test_data):\n",
        "    \"\"\"\n",
        "    model : Trained model\n",
        "    test_data : test data = dataset[30000//batch_size:]\n",
        "    input_shape :input size of images\n",
        "    compression_size :  size of bottleneck\n",
        "    \"\"\"\n",
        "    e = math.e\n",
        "    learning_rate = [0.0008,0.0009,0.00095,0.0001]\n",
        "    n_epochs_lst = [3,5]\n",
        "    batch_size_lst = [500,800,1000,1300,1500]\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    loss = float('inf')\n",
        "    best_lr = 0\n",
        "    update_interval = 100\n",
        "    best_batch = 0\n",
        "    best_n_epochs = 0\n",
        "    for lr in learning_rate:\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "        for n_epochs in n_epochs_lst :\n",
        "            trained_model, losses = training('model3',model, loss_function, optimizer, train_dataloader, n_epochs, update_interval)\n",
        "            for batch_size in batch_size_lst:\n",
        "                print(batch_size)\n",
        "                print(lr)\n",
        "                print(n_epochs)\n",
        "                test_loss, test_accuracy = testing('model3', model, loss_function, test_dataloader)\n",
        "                if test_loss <= loss:\n",
        "                    best_lr = lr\n",
        "                    best_batch = batch_size\n",
        "                    best_n_epochs = n_epochs\n",
        "                    loss = test_loss\n",
        "\n",
        "    return best_lr , best_batch, best_n_epochs,loss\n",
        "\n",
        "best_lr,best_batch_size, best_n_epochs,loss = grid_search(trained_model4, 784, 2, test_dataset)\n",
        "print(best_lr,best_batch_size, best_n_epochs, loss)"
      ],
      "id": "ac53287e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66d53d58"
      },
      "outputs": [],
      "source": [
        "def train_and_test(modelname,model, loss_function, optimizer, batch_size, update_interval, n_epochs):\n",
        "\n",
        "    '''\n",
        "    This will use your/my methods to create a dataloader, train a gven model, and then test its performance\n",
        "\n",
        "    Again, since I gave this to you for free you have to promise to look at it and try to understand it\n",
        "    '''\n",
        "\n",
        "    _, train_dataloader = load_mnist(batch_size=batch_size, train=True)\n",
        "    trained_model, losses = training(modelname,model, loss_function, optimizer, train_dataloader, n_epochs=n_epochs, update_interval=update_interval)\n",
        "\n",
        "    # Specify a path\n",
        "    PATH = \"state_dict_{}.pt\".format(modelname)\n",
        "\n",
        "    # Save\n",
        "    torch.save(trained_model.state_dict(), PATH)\n",
        "    _, test_dataloader = load_mnist(batch_size=10000, train=False)\n",
        "    test_acc, test_loss = testing(modelname, trained_model, loss_function, test_dataloader)\n",
        "\n",
        "    plt.plot(np.arange(len(losses)) * batch_size * update_interval, losses, color=\"b\", label=\"train loss\")\n",
        "    plt.hlines(test_loss, 0, len(losses) * batch_size * update_interval, color='r', label=\"test loss\")\n",
        "    plt.legend()\n",
        "    plt.title(\"training curve\")\n",
        "    plt.xlabel(\"number of images trained on\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.savefig('lr{} Single Model test_acc{} test_loss{}.png'.format(0.08,test_acc,test_loss))\n",
        "    plt.show()\n",
        "\n",
        "    return trained_model, test_loss\n",
        "\n",
        ""
      ],
      "id": "66d53d58"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "693d50c6"
      },
      "outputs": [],
      "source": [
        "# Getting Train and Test for the BASELINE Model\n",
        "lr = 0.06               # The size of the step taken when doing gradient descent\n",
        "batch_size = 100      # The number of images being trained on at once\n",
        "update_interval = 400      # The number of times we train through the entire dataset\n",
        "model = MyMLP(784, 10)\n",
        "n_epochs = 10\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "_, _ = train_and_test('model',model, loss_function, optimizer, batch_size=batch_size, update_interval=update_interval, n_epochs=n_epochs)"
      ],
      "id": "693d50c6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b52f18f"
      },
      "outputs": [],
      "source": [
        "# # https://stackoverflow.com/questions/63975130/how-to-get-only-specific-classes-from-pytorchs-fashionmnist-dataset\n",
        "# dataset_full = train_dataset\n",
        "# #Selecting classes 7, 2, 5 and 6\n",
        "# idx = (dataset_full.targets==7) | (dataset_full.targets==2) | (dataset_full.targets==5) | (dataset_full.targets==6)\n",
        "# dataset_full.targets = dataset_full.targets[idx]\n",
        "# dataset_full.data = dataset_full.data[idx]"
      ],
      "id": "4b52f18f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "561d152b"
      },
      "outputs": [],
      "source": [
        "#  EXPERIMENT 1 :\n",
        "def experiment_1(model):\n",
        "    \"\"\"\n",
        "    Train 4 similar models on different parts of the MNIST dataset and combine the output\n",
        "    Same HyperParameters for every model\n",
        "    \"\"\"\n",
        "    lr = 0.08               # The size of the step taken when doing gradient descent\n",
        "    batch_size = 100       # The number of images being trained on at once\n",
        "    update_interval = 100   # The number of batches trained on before recording loss\n",
        "    n_epochs = 30  # The number of times we train through the entire dataset\n",
        "#     Train and Test 4 different models\n",
        "    model1 = MyMLP(784, 1)\n",
        "    model2 = MyMLP(784, 1)\n",
        "    model3 = MyMLP(784, 1)\n",
        "    model4 = MyMLP(784, 1)\n",
        "\n",
        "experiment_1(MyMLP)"
      ],
      "id": "561d152b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66d8effb"
      },
      "outputs": [],
      "source": [
        "# Experiment 2:\n",
        "def experiment_1(self, model):\n",
        "    \"\"\"\n",
        "    Train 4 similar models on different parts of the MNIST dataset and combine the output\n",
        "    Same HyperParameters for every model\n",
        "    \"\"\"\n",
        "    lr = 0.08               # The size of the step taken when doing gradient descent\n",
        "    batch_size = 100       # The number of images being trained on at once\n",
        "    update_interval = 100   # The number of batches trained on before recording loss\n",
        "    n_epochs = 30  # The number of times we train through the entire dataset\n",
        "#     Train and Test 4 different models\n",
        "    model1 = MyMLP(784, 2)\n",
        "    model2 = MyMLP(784, 2)\n",
        "    model3 = MyMLP(784, 2)\n",
        "    model4 = MyMLP(784, 2)\n",
        "\n",
        "    loss_function = nn.BCELoss()\n",
        "#     Binary Cross Entropy loss\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    _, _ = train_and_test(model1, loss_function, optimizer, batch_size=batch_size, update_interval=update_interval, n_epochs=n_epochs)\n",
        ""
      ],
      "id": "66d8effb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cca02c0"
      },
      "outputs": [],
      "source": [
        "#  Change the labels\n",
        "# Have 4 modules : if module 1 : change the label to 0 if it is in say group [2,3,4,5,6] , if not make it output a 1\n",
        "# Create 4 modules like this\n",
        "# And Map each output 0 and 1 for each module to a unique number\n",
        "# {9 : 1111}"
      ],
      "id": "0cca02c0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd866fda"
      },
      "outputs": [],
      "source": [
        "# Train 1 model to predict 4 different ways\n",
        "# Recurrent Predictions into Groups :\n",
        "# Group 1 : [0 -5][5-9]\n",
        "# Say the model selects [5-9]\n",
        "# Now make the model predict [5-7] and [8-9] as groups\n",
        "#  keep splitting things until you get 1 prediciton  == label"
      ],
      "id": "bd866fda"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb01b2b5"
      },
      "outputs": [],
      "source": [
        "# def training():\n",
        "# \"Final String \" 0111 :  9\n",
        "# input(0,1,1,1)\n",
        "# new_label = 9 .convert(binary)\n",
        "# class MyEnsemble(nn.Module):\n",
        "#     def __init__(self, outA, outB, outC, outD,input_shape):\n",
        "#         super(MyEnsemble, self).__init__()\n",
        "#         self.lin1 = nn.Linear(inpt_shape,1)\n",
        "#     def forward(self, x):\n",
        "#         return self.lin1(x)\n",
        "\n",
        "# modelA = MyModelA()\n",
        "# modelB = MyModelB()\n",
        "# # Load state dicts\n",
        "# modelA.load_state_dict(torch.load(PATH))\n",
        "# modelB.load_state_dict(torch.load(PATH))\n",
        "\n",
        "# model = MyEnsemble(modelA, modelB)\n",
        "# x1, x2 = torch.randn(1, 10), torch.randn(1, 20)\n",
        "# output = model(x1, x2)"
      ],
      "id": "fb01b2b5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3fb92e5"
      },
      "outputs": [],
      "source": [
        "lr = 0.008            # The size of the step taken when doing gradient descent\n",
        "batch_size = 1        # The number of images being trained on at once\n",
        "update_interval = 300   # The number of batches trained on before recording loss\n",
        "n_epochs = 3            # The number of times we train through the entire dataset\n",
        "\n",
        "train_dataset, train_dataloader = load_mnist(batch_size=batch_size, train=True)\n",
        "\n",
        "model = MyMLP(784, 2)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "id": "f3fb92e5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af982605"
      },
      "outputs": [],
      "source": [
        "def new_training(train_dataloader, n_epochs, update_interval):\n",
        "    acc = []\n",
        "    part_loss = []\n",
        "    num_correct = 0\n",
        "    for n in range(n_epochs):\n",
        "        for i, (image, label) in enumerate(tqdm(iter(train_dataloader))):\n",
        "\n",
        "            # TODO Complete the training loop using the instructions above\n",
        "            # Hint: the above code essentially does one training step\n",
        "            ##############################################################\n",
        "            out1 = trained_model1(image)\n",
        "            out2 = trained_model2(image)\n",
        "            out3 = trained_model3(image)\n",
        "            out4 = trained_model4(image)\n",
        "            res = []\n",
        "            for i in range(len(out1)):\n",
        "              a = str(torch.argmax(out1[i]).numpy()) + str(torch.argmax(out2[i]).numpy()) + str(torch.argmax(out3[i]).numpy()) + str(torch.argmax(out4[i]).numpy())\n",
        "              res.append(int(a))\n",
        "            # print(res)\n",
        "            my_output = res\n",
        "            new_label = torch.Tensor([int(mapping[int(l)]) for l in label]).long()\n",
        "            num_correct = 0\n",
        "            # print(new_label)\n",
        "            for index in range(len(new_label)):\n",
        "              if my_output[index] == new_label[index] :\n",
        "                num_correct = num_correct + 1\n",
        "\n",
        "            acc.append(num_correct/len(new_label))\n",
        "            ##############################################################\n",
        "    return acc"
      ],
      "id": "af982605"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59f8d53f"
      },
      "outputs": [],
      "source": [],
      "id": "59f8d53f"
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Performance on Test Set\n",
        "_, test_dataloader = load_mnist(batch_size=batch_size, train=False)\n",
        "acc = new_training(test_dataloader, 3, 300)\n",
        "plt.plot(acc)\n",
        "plt.title(\"Combined Labels of 4 Models Plot of Accuracy with Test Dataset\")\n",
        "plt.xlabel(\"number of images trained on\")\n",
        "plt.ylabel(\" Test Accuracy\")\n",
        "final_accuracy = acc[-1]\n",
        "print(\"final accuracy\" ,final_accuracy)"
      ],
      "metadata": {
        "id": "xXm-vnVjK64N"
      },
      "id": "xXm-vnVjK64N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "782f6e46"
      },
      "outputs": [],
      "source": [
        "#   Balanced Data (Li and etc) vs Our Binary mapping right now\n",
        "#   no of epochs should be less\n",
        "#  Testing Accuracy , Learning Curve\n",
        "#  Also how will the model perform if given 1000  Exampls, vs 6000 Examples etc .\n",
        "# Compare this to the baseline model\n",
        "\n",
        "# Train 4 models indvidually\n",
        "# Just test the model with combination of outputs of 4 models(no training required, just combine the outputs)"
      ],
      "id": "782f6e46"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_l1l3LAwdy1R"
      },
      "outputs": [],
      "source": [
        "# The model Capability may not be enough : Try the Same with ResNets"
      ],
      "id": "_l1l3LAwdy1R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d208d01d"
      },
      "outputs": [],
      "source": [
        "#  Group similar numbers together and test it out"
      ],
      "id": "d208d01d"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}